{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50e13eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torchmetrics import Accuracy, Metric\n",
    "import torchmetrics\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import itertools\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchmetrics import Accuracy \n",
    "cudnn.benchmark = True\n",
    "import csv\n",
    "from torch.nn import init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae8b2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4d3530",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE_SEG = 0.001\n",
    "BCE_LOSS = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89368aa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image_dir = 'overlap_patch/img'\n",
    "mask_dir = 'overlap_patch/mask'\n",
    "\n",
    "image_dataset = [] \n",
    "mask_dataset = []\n",
    "\n",
    "imgNames = os.listdir(image_dir)\n",
    "imgAddr = image_dir + '/'\n",
    "maskAddr = mask_dir + '/'\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in tqdm(range(len(imgNames)), desc=\"Processing images\"):\n",
    "# for i in tqdm(range(500), desc=\"Processing images\"):\n",
    "    try:\n",
    "        mask = cv2.imread(maskAddr + imgNames[i], 0) \n",
    "        mask = Image.fromarray(mask)\n",
    "        mask_array = np.array(mask)\n",
    "        \n",
    "        if np.sum(mask_array) > 8000:\n",
    "            image = cv2.imread(imgAddr + imgNames[i], cv2.IMREAD_COLOR)  \n",
    "            image = Image.fromarray(image)\n",
    "\n",
    "            image_dataset.append(np.array(image))\n",
    "            mask_dataset.append(np.array(mask))\n",
    "            count += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {imgNames[i]}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f0d296",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = np.array(image_dataset)  \n",
    "mask_dataset = np.array(mask_dataset)    \n",
    "\n",
    "image_dataset = np.expand_dims(image_dataset, axis=3)\n",
    "image_dataset = np.squeeze(image_dataset)\n",
    "mask_dataset = np.expand_dims(mask_dataset, axis=3)\n",
    "\n",
    "source_xtrain, source_xtest, source_ytrain, source_ytest = train_test_split(\n",
    "    image_dataset, mask_dataset, test_size=0.3, random_state=44, shuffle=True)\n",
    "\n",
    "source_xval, source_xtest, source_yval, source_ytest = train_test_split(\n",
    "    source_xtest, source_ytest, test_size=0.2, random_state=44, shuffle=True)\n",
    "\n",
    "print(f\"Total processed images: {count}\")\n",
    "print(f\"Training set size: {len(source_xtrain)}, Validation set size: {len(source_xval)}, Test set size: {len(source_xtest)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea79cef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageMaskDataset(Dataset):\n",
    "    def __init__(self, images, masks):\n",
    "        self.images = torch.tensor(images, dtype=torch.float32)\n",
    "        self.masks = torch.tensor(masks, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.images[idx], self.masks[idx]\n",
    "\n",
    "train_dataset_s = ImageMaskDataset(source_xtrain, source_ytrain)\n",
    "val_dataset_s = ImageMaskDataset(source_xval, source_yval)\n",
    "test_dataset_s = ImageMaskDataset(source_xtest, source_ytest)\n",
    "\n",
    "train_loader_s = DataLoader(train_dataset_s, batch_size=8, shuffle=True, num_workers=4)\n",
    "val_loader_s = DataLoader(val_dataset_s, batch_size=8, shuffle=False, num_workers=4)\n",
    "test_loader_s = DataLoader(test_dataset_s, batch_size=1, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2402b7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_pred, y_true):\n",
    "    smooth = 1.\n",
    "\n",
    "    iflat = y_pred.view(-1)\n",
    "    tflat = y_true.view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "\n",
    "    return (2. * intersection + smooth) / (iflat.sum() + tflat.sum() + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfbf5ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class conv_block(nn.Module):\n",
    "    def __init__(self,ch_in,ch_out):\n",
    "        super(conv_block,self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(ch_in, ch_out, kernel_size=3,stride=1,padding=1,bias=True),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(ch_out, ch_out, kernel_size=3,stride=1,padding=1,bias=True),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "class up_conv(nn.Module):\n",
    "    def __init__(self,ch_in,ch_out):\n",
    "        super(up_conv,self).__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(ch_in,ch_out,kernel_size=3,stride=1,padding=1,bias=True),\n",
    "\t\t    nn.BatchNorm2d(ch_out),\n",
    "\t\t\tnn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.up(x)\n",
    "        return x\n",
    "\n",
    "class U_Net(nn.Module):\n",
    "    def __init__(self,img_ch=3,output_ch=1):\n",
    "        super(U_Net,self).__init__()\n",
    "        \n",
    "        self.Maxpool = nn.MaxPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        self.Conv1 = conv_block(ch_in=img_ch,ch_out=64)\n",
    "        self.Conv2 = conv_block(ch_in=64,ch_out=128)\n",
    "        self.Conv3 = conv_block(ch_in=128,ch_out=256)\n",
    "        self.Conv4 = conv_block(ch_in=256,ch_out=512)\n",
    "        self.Conv5 = conv_block(ch_in=512,ch_out=1024)\n",
    "\n",
    "        self.Up5 = up_conv(ch_in=1024,ch_out=512)\n",
    "        self.Up_conv5 = conv_block(ch_in=1024, ch_out=512)\n",
    "\n",
    "        self.Up4 = up_conv(ch_in=512,ch_out=256)\n",
    "        self.Up_conv4 = conv_block(ch_in=512, ch_out=256)\n",
    "        \n",
    "        self.Up3 = up_conv(ch_in=256,ch_out=128)\n",
    "        self.Up_conv3 = conv_block(ch_in=256, ch_out=128)\n",
    "        \n",
    "        self.Up2 = up_conv(ch_in=128,ch_out=64)\n",
    "        self.Up_conv2 = conv_block(ch_in=128, ch_out=64)\n",
    "\n",
    "        self.Conv_1x1 = nn.Conv2d(64,output_ch,kernel_size=1,stride=1,padding=0)\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "        # encoding path\n",
    "        x1 = self.Conv1(x)\n",
    "\n",
    "        x2 = self.Maxpool(x1)\n",
    "        x2 = self.Conv2(x2)\n",
    "        \n",
    "        x3 = self.Maxpool(x2)\n",
    "        x3 = self.Conv3(x3)\n",
    "\n",
    "        x4 = self.Maxpool(x3)\n",
    "        x4 = self.Conv4(x4)\n",
    "\n",
    "        x5 = self.Maxpool(x4)\n",
    "        x5 = self.Conv5(x5)\n",
    "\n",
    "        # decoding + concat path\n",
    "        d5 = self.Up5(x5)\n",
    "        d5 = torch.cat((x4,d5),dim=1)\n",
    "        \n",
    "        d5 = self.Up_conv5(d5)\n",
    "        \n",
    "        d4 = self.Up4(d5)\n",
    "        d4 = torch.cat((x3,d4),dim=1)\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        d3 = torch.cat((x2,d3),dim=1)\n",
    "        d3 = self.Up_conv3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        d2 = torch.cat((x1,d2),dim=1)\n",
    "        d2 = self.Up_conv2(d2)\n",
    "\n",
    "        d1 = self.Conv_1x1(d2)\n",
    "        d1 = d1.permute(0, 2, 3, 1)\n",
    "        return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd08d5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 150\n",
    "model_seg = U_Net()\n",
    "model_seg.train()\n",
    "model_seg = model_seg.to(device)\n",
    "\n",
    "optimizer_seg = optim.Adam(model_seg.parameters(), lr=LEARNING_RATE_SEG, betas=(0.9, 0.999))\n",
    "scheduler = ReduceLROnPlateau(optimizer_seg, mode='min', factor=0.2, patience=5, min_lr = 1e-5, verbose=True)\n",
    "\n",
    "accuracy_train_metric = torchmetrics.Accuracy(task='binary').to(device)\n",
    "accuracy_val_metric = torchmetrics.Accuracy(task='binary').to(device)\n",
    "log_name = 'baseunet3001'\n",
    "writer = SummaryWriter('runs/' + log_name)\n",
    "csv_file = open(log_name + '.csv', 'w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow([\n",
    "    'Epoch', 'Training Seg Loss', 'Validation Seg Loss',\n",
    "    'Training Dice Score', 'Validation Dice Score',\n",
    "    'Training Accuracy', 'Validation Accuracy',\n",
    "    'Learning Rate', 'Time (mins)'\n",
    "])\n",
    "for epoch in range(epochs):\n",
    "    model_seg.train()\n",
    "    seg_loss_b = []\n",
    "    dice_b = []\n",
    "    epoch_start_time = time.time()\n",
    "    for i, (batch_s) in enumerate(train_loader_s):\n",
    "        optimizer_seg.zero_grad()\n",
    "        image_s, label_s = batch_s\n",
    "        image_s, label_s = image_s.to(device), label_s.to(device)\n",
    "\n",
    "        pred_s = model_seg(image_s)\n",
    "        loss_seg = BCE_LOSS(pred_s, label_s)\n",
    "\n",
    "        pred_s = torch.sigmoid(pred_s)\n",
    "        pred_binary = (pred_s > 0.5).float()\n",
    "        dice_loss = dice_coef(pred_binary, label_s)\n",
    "        accuracy_train_metric.update(pred_binary, label_s)\n",
    "\n",
    "        loss_seg.backward()\n",
    "        optimizer_seg.step()\n",
    "\n",
    "        seg_loss_b.append(loss_seg.item())\n",
    "        dice_b.append(dice_loss.item())\n",
    "\n",
    "    # Training metrics\n",
    "    segloss_train = np.mean(seg_loss_b)\n",
    "    diceScore_train = np.mean(dice_b)\n",
    "    accuracy_train = accuracy_train_metric.compute().item()\n",
    "    accuracy_train_metric.reset()\n",
    "\n",
    "    model_seg.eval()\n",
    "    seg_loss_b = []\n",
    "    dice_b = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, vdata in enumerate(val_loader_s):\n",
    "            vinputs, vlabels = vdata\n",
    "            vinputs, vlabels = vinputs.to(device), vlabels.to(device)\n",
    "\n",
    "            voutputs = model_seg(vinputs)\n",
    "            vloss = BCE_LOSS(voutputs, vlabels)\n",
    "\n",
    "            voutputs = torch.sigmoid(voutputs)\n",
    "            voutputs_binary = (voutputs > 0.5).float()\n",
    "            dice_loss = dice_coef(voutputs_binary, vlabels)\n",
    "            accuracy_val_metric.update(voutputs_binary, vlabels)\n",
    "            seg_loss_b.append(vloss.item())\n",
    "            dice_b.append(dice_loss.item())\n",
    "\n",
    "    segloss_val = np.mean(seg_loss_b)\n",
    "    diceScore_val = np.mean(dice_b)\n",
    "    accuracy_val = accuracy_val_metric.compute().item()\n",
    "    accuracy_val_metric.reset()\n",
    "    \n",
    "    epoch_end_time = time.time()\n",
    "    epoch_time = (epoch_end_time - epoch_start_time) / 60\n",
    "    print('[Epoch: {}, {:.2f}mins] Training Seg Loss: {:.2f}, Validation Seg Loss: {:.2f}, '\n",
    "          'Training Dice Score: {:.2f}, Validation Dice Score: {:.2f}, '\n",
    "          'Training Accuracy: {:.2f}, Validation Accuracy: {:.2f}'.format(\n",
    "          epoch+1, epoch_time, segloss_train, segloss_val, diceScore_train, diceScore_val, accuracy_train, accuracy_val))\n",
    "    \n",
    "    writer.add_scalar('Segmentation Loss/train', segloss_train, epoch+1)\n",
    "    writer.add_scalar('Segmentation Loss/validation', segloss_val, epoch+1)\n",
    "    writer.add_scalar('Segmentation Accuracy/train', accuracy_train, epoch+1)\n",
    "    writer.add_scalar('Segmentation Accuracy/validation', accuracy_val, epoch+1)\n",
    "    writer.add_scalar('Dice Score/train', diceScore_train, epoch+1)\n",
    "    writer.add_scalar('Dice Score/validation', diceScore_val, epoch+1)\n",
    "    writer.add_scalar('Learning Rate', scheduler.optimizer.param_groups[0]['lr'], epoch+1)\n",
    "    writer.add_scalar('Time', epoch_time, epoch+1)\n",
    "    # Step scheduler\n",
    "    scheduler.step(segloss_val)\n",
    "    \n",
    "    csv_writer.writerow([\n",
    "        epoch + 1, segloss_train, segloss_val, \n",
    "        diceScore_train, diceScore_val, \n",
    "        accuracy_train, accuracy_val, \n",
    "        scheduler.optimizer.param_groups[0]['lr'], epoch_time\n",
    "    ])\n",
    "    csv_file.flush() \n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        torch.save(model_seg, log_name + '.pth')\n",
    "writer.close()\n",
    "csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0094d92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seg.eval()\n",
    "def visualize_prediction(test_image, ground_truth, predicted_mask, dice_score):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # Test Image\n",
    "    axes[0].imshow(test_image)  # Permute for correct shape (H, W, C)\n",
    "    axes[0].set_title('Test Image')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Ground Truth\n",
    "    axes[1].imshow(ground_truth)  # Squeeze to remove channel dimension\n",
    "    axes[1].set_title('Ground Truth')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # Predicted Mask\n",
    "    axes[2].imshow(predicted_mask)  # Squeeze to remove channel dimension\n",
    "    axes[2].set_title(f'Predicted Mask\\nDice Coeff: {dice_score:.4f}')\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "dice_scores = []   \n",
    "with torch.no_grad():\n",
    "    for i, (test_image, ground_truth) in enumerate(test_loader_s):\n",
    "        test_image = test_image.to(device)\n",
    "        ground_truth = ground_truth.to(device)\n",
    "#         test_image = nor\n",
    "        preds = model_seg(test_image)\n",
    "        preds = (preds > 0.5).float()\n",
    "        tm = test_image[0].cpu().numpy().astype('uint8')\n",
    "        dice_score = dice_coef(ground_truth, preds)\n",
    "        dice_scores.append(dice_score.cpu().numpy())\n",
    "        visualize_prediction(tm, ground_truth[0].cpu().numpy(), preds[0].cpu().numpy(), dice_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a89e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.mean(dice_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
