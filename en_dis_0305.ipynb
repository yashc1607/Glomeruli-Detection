{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May  2 03:25:46 2025       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.216.03             Driver Version: 535.216.03   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA A100 80GB PCIe          On  | 00000000:4B:00.0 Off |                    0 |\n",
      "| N/A   38C    P0              43W / 300W |     17MiB / 81920MiB |      0%      Default |\n",
      "|                                         |                      |             Disabled |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import itertools \n",
    "import numpy as np\n",
    "import imagecodecs\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import tifffile as tifi\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchmetrics import Accuracy, Metric\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA_ADV = 0.1\n",
    "MAX_LR = 0.00001\n",
    "LEARNING_RATE_SEG = 0.00001\n",
    "LEARNING_RATE_DIS = 0.0001\n",
    "BATCH_SIZE = 8\n",
    "BCE_LOSS = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ImageMaskDataset(Dataset):\n",
    "#     def __init__(self, images, masks):\n",
    "#         self.images = torch.tensor(images, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "#         self.masks = torch.tensor(masks, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.images)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         return self.images[idx], self.masks[idx]\n",
    "\n",
    "class ImageMaskDataset(Dataset):\n",
    "    def __init__(self, images, masks):\n",
    "        self.images = images  # Keep as NumPy arrays, not torch tensors\n",
    "        self.masks = masks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = torch.from_numpy(self.images[idx]).permute(2, 0, 1).float()\n",
    "        mask = torch.from_numpy(self.masks[idx]).permute(2, 0, 1).float()\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  98%|████████████████████████████████████████████████████████▌ | 12919/13239 [07:34<00:10, 30.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing .ipynb_checkpoints: 'NoneType' object has no attribute '__array_interface__'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████████████████████████████████████████████████████| 13239/13239 [07:47<00:00, 28.34it/s]\n"
     ]
    }
   ],
   "source": [
    "image_dir = 'overlap_patch/img'\n",
    "mask_dir = 'overlap_patch/mask'\n",
    "\n",
    "image_dataset = [] \n",
    "mask_dataset = []\n",
    "\n",
    "imgNames = os.listdir(image_dir)\n",
    "imgAddr = image_dir + '/'\n",
    "maskAddr = mask_dir + '/'\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in tqdm(range(len(imgNames)), desc=\"Processing images\"):\n",
    "# for i in tqdm(range(100), desc=\"Processing images\"):\n",
    "    try:\n",
    "        mask = cv2.imread(maskAddr + imgNames[i], 0) \n",
    "        mask = Image.fromarray(mask)\n",
    "        mask_array = np.array(mask)\n",
    "        \n",
    "        if np.sum(mask_array) > 8000:\n",
    "            image = cv2.imread(imgAddr + imgNames[i], cv2.IMREAD_COLOR)  \n",
    "            image = Image.fromarray(image)\n",
    "            image_dataset.append(np.array(image))\n",
    "            mask_dataset.append(np.array(mask))\n",
    "            count += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {imgNames[i]}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total processed images: 10367\n",
      "Training set size: 7256, Validation set size: 2488, Test set size: 623\n"
     ]
    }
   ],
   "source": [
    "image_dataset = np.array(image_dataset)  \n",
    "mask_dataset = np.array(mask_dataset)    \n",
    "\n",
    "image_dataset = np.expand_dims(image_dataset, axis=3)\n",
    "image_dataset = np.squeeze(image_dataset)\n",
    "mask_dataset = np.expand_dims(mask_dataset, axis=3)\n",
    "\n",
    "source_img_train, source_img_test, source_mask_train, source_mask_test = train_test_split(\n",
    "    image_dataset, mask_dataset, test_size=0.3, random_state=44, shuffle=True)\n",
    "\n",
    "source_img_val, source_img_test, source_mask_val, source_mask_test = train_test_split(\n",
    "    source_img_test, source_mask_test, test_size=0.2, random_state=44, shuffle=True)\n",
    "\n",
    "print(f\"Total processed images: {count}\")\n",
    "print(f\"Training set size: {len(source_img_train)}, Validation set size: {len(source_img_val)}, Test set size: {len(source_img_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset_s = ImageMaskDataset(source_img_train, source_mask_train)\n",
    "# val_dataset_s = ImageMaskDataset(source_img_val, source_mask_val)\n",
    "test_dataset_s = ImageMaskDataset(source_img_test, source_mask_test)\n",
    "\n",
    "# train_loader_s = DataLoader(train_dataset_s, batch_size=8, shuffle=True, num_workers=4, pin_memory=True)\n",
    "# val_loader_s = DataLoader(val_dataset_s, batch_size=8, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader_s = DataLoader(test_dataset_s, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del image_dataset, mask_dataset, source_img_train, source_img_test, source_mask_train, source_mask_test, source_img_val, source_mask_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  98%|██████████████████████████████████████████████████████████▌ | 2432/2493 [01:41<00:02, 23.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing .ipynb_checkpoints: '>' not supported between instances of 'NoneType' and 'int'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|████████████████████████████████████████████████████████████| 2493/2493 [01:44<00:00, 23.87it/s]\n"
     ]
    }
   ],
   "source": [
    "target_image_dir = 'aidpath_target/images_512'\n",
    "target_mask_dir = 'aidpath_target/masks_512'\n",
    "target_image = [] \n",
    "target_mask= []\n",
    "\n",
    "imgNames = os.listdir(target_image_dir)\n",
    "imgAddr = target_image_dir + '/'\n",
    "maskAddr = target_mask_dir + '/'\n",
    "count = 0\n",
    "\n",
    "for i in tqdm(range(len(imgNames)), desc=\"Processing images\"):\n",
    "# for i in tqdm(range(100), desc=\"Processing images\"):\n",
    "    try:\n",
    "        mask = cv2.imread(maskAddr + imgNames[i], 0) \n",
    "#         mask = Image.fromarray(mask)\n",
    "        mask_array = np.array(mask)\n",
    "        \n",
    "        if np.sum(mask_array) > 0:\n",
    "            image = cv2.imread(imgAddr + imgNames[i], cv2.IMREAD_COLOR)  \n",
    "            mask = mask / 255.\n",
    "            mask = (mask > 0.5).astype(int)\n",
    "            target_image.append(np.array(image))\n",
    "            target_mask.append(np.array(mask))\n",
    "#             break\n",
    "            count += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {imgNames[i]}: {e}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  'SESCAM_2_0.svs', 'SESCAM_3_0.svs', 'SESCAM_4_0.svs', 'SESCAM_7_0.svs', 'SESCAM_8_0.svs','VUHSK_1912.svs', 'VUHSK_1992.svs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total processed images: 2492\n",
      "Training set size: 2242, Validation set size: 200, Test set size: 50\n"
     ]
    }
   ],
   "source": [
    "target_image = np.array(target_image)  \n",
    "target_mask = np.array(target_mask)    \n",
    "\n",
    "target_image = np.expand_dims(target_image, axis=3)\n",
    "target_image = np.squeeze(target_image)\n",
    "target_mask = np.expand_dims(target_mask, axis=3)\n",
    "\n",
    "target_train_image, target_test_image, target_train_mask, target_test_mask = train_test_split(\n",
    "    target_image, target_mask, test_size=0.1, random_state=44, shuffle=True)\n",
    "\n",
    "target_val_image, target_test_image, target_val_mask, target_test_mask = train_test_split(\n",
    "    target_test_image, target_test_mask, test_size=0.2, random_state=44, shuffle=True)\n",
    "\n",
    "print(f\"Total processed images: {count}\")\n",
    "print(f\"Training set size: {len(target_train_image)}, Validation set size: {len(target_val_image)}, Test set size: {len(target_test_image)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_dataset_t = ImageMaskDataset(target_train_image, target_train_mask)\n",
    "# val_dataset_t = ImageMaskDataset(target_val_image, target_val_mask)\n",
    "test_dataset_t = ImageMaskDataset(target_test_image, target_test_mask)\n",
    "\n",
    "# train_loader_t = DataLoader(train_dataset_t, batch_size=8, shuffle=True, num_workers=4, pin_memory=True)\n",
    "# val_loader_t = DataLoader(val_dataset_t, batch_size=8, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader_t = DataLoader(test_dataset_t, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del target_image, target_mask, target_train_image, target_test_image, target_train_mask, target_test_mask, target_val_image, target_val_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(ch_out)\n",
    "        )\n",
    "        self.residual = nn.Conv2d(ch_in, ch_out, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = self.residual(x)\n",
    "        x = self.conv(x)\n",
    "        x += residual  # Residual connection\n",
    "        return self.relu(x)\n",
    "\n",
    "class up_conv(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super(up_conv, self).__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),A\n",
    "            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.up(x)\n",
    "\n",
    "\n",
    "class encoder(nn.Module):\n",
    "    def __init__(self, img_ch=3, output_ch=1):\n",
    "        super(encoder, self).__init__()\n",
    "        \n",
    "        self.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.ResBlock1 = ResidualBlock(ch_in=img_ch, ch_out=64)\n",
    "        self.ResBlock2 = ResidualBlock(ch_in=64, ch_out=128)\n",
    "        self.ResBlock3 = ResidualBlock(ch_in=128, ch_out=256)\n",
    "        self.ResBlock4 = ResidualBlock(ch_in=256, ch_out=512)\n",
    "        self.ResBlock5 = ResidualBlock(ch_in=512, ch_out=1024)\n",
    "        \n",
    "        self.Up5 = up_conv(ch_in=1024, ch_out=512)\n",
    "        self.Up_ResBlock5 = ResidualBlock(ch_in=1024, ch_out=512)\n",
    "        \n",
    "        self.Up4 = up_conv(ch_in=512, ch_out=256)\n",
    "        self.Up_ResBlock4 = ResidualBlock(ch_in=512, ch_out=256)\n",
    "        \n",
    "        self.Up3 = up_conv(ch_in=256, ch_out=128)\n",
    "        self.Up_ResBlock3 = ResidualBlock(ch_in=256, ch_out=128)\n",
    "        \n",
    "        self.Up2 = up_conv(ch_in=128, ch_out=64)\n",
    "        self.Up_ResBlock2 = ResidualBlock(ch_in=128, ch_out=64)\n",
    "\n",
    "        self.Conv_1x1 = nn.Conv2d(64, output_ch, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoding path\n",
    "#         x = x.permute(0, 3, 1, 2)\n",
    "        x1 = self.ResBlock1(x)\n",
    "        x2 = self.Maxpool(x1)\n",
    "        x2 = self.ResBlock2(x2)\n",
    "        \n",
    "        x3 = self.Maxpool(x2)\n",
    "        x3 = self.ResBlock3(x3)\n",
    "\n",
    "        x4 = self.Maxpool(x3)\n",
    "        x4 = self.ResBlock4(x4)\n",
    "\n",
    "        x5 = self.Maxpool(x4)\n",
    "        x5 = self.ResBlock5(x5)\n",
    "\n",
    "        # Decoding + concat path\n",
    "        d5 = self.Up5(x5)\n",
    "        d5 = torch.cat((x4, d5), dim=1)\n",
    "        d5 = self.Up_ResBlock5(d5)\n",
    "        \n",
    "        d4 = self.Up4(d5)\n",
    "        d4 = torch.cat((x3, d4), dim=1)\n",
    "        d4 = self.Up_ResBlock4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        d3 = torch.cat((x2, d3), dim=1)\n",
    "        d3 = self.Up_ResBlock3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        d2 = torch.cat((x1, d2), dim=1)\n",
    "        d2 = self.Up_ResBlock2(d2)\n",
    "\n",
    "        d1 = self.Conv_1x1(d2)\n",
    "#         d1 = d1.permute(0, 2, 3, 1)\n",
    "        return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCDiscriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, ndf=64):\n",
    "        super(FCDiscriminator, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(num_classes, ndf, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(ndf, ndf * 2, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(ndf * 2, ndf * 4, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(ndf * 4, ndf * 8, kernel_size=4, stride=2, padding=1)\n",
    "        self.classifier = nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=2, padding=1)\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = x.permute(0, 3, 1, 2)\n",
    "        x = self.conv1(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.classifier(x)\n",
    "#         x = x.permute(0, 2, 3, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_pred, y_true):\n",
    "    smooth = 1.\n",
    "\n",
    "    iflat = y_pred.view(-1)\n",
    "    tflat = y_true.view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "\n",
    "    return ((2. * intersection) + smooth) / (iflat.sum() + tflat.sum() + smooth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diceLoss(y_pred, y_true):\n",
    "    smooth = 1.\n",
    "\n",
    "    iflat = y_pred.view(-1)\n",
    "    tflat = y_true.view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "\n",
    "    return 1.0 - ((2. * intersection) + smooth) / (iflat.sum() + tflat.sum() + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_image(image):\n",
    "    min_val = image.min(dim=-1, keepdim=True)[0].min(dim=-2, keepdim=True)[0]  # Get min per channel\n",
    "    max_val = image.max(dim=-1, keepdim=True)[0].max(dim=-2, keepdim=True)[0]  # Get max per channel\n",
    "    \n",
    "    normalized_img = (image - min_val) / (max_val - min_val + 1e-8)  # Add epsilon to avoid division by zero\n",
    "    return normalized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_loader_cycle = itertools.cycle(train_loader_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valtarget_loader_cycle = itertools.cycle(val_loader_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "source_label = 0\n",
    "target_label = 1\n",
    "model_seg = encoder()\n",
    "model_dismain = FCDiscriminator(1)\n",
    "model_seg = model_seg.train()\n",
    "model_dismain = model_dismain.train()\n",
    "model_seg = model_seg.to(device)\n",
    "model_dismain = model_dismain.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_seg = optim.Adam(model_seg.parameters(), lr=LEARNING_RATE_SEG, betas=(0.9, 0.999))\n",
    "# scheduler_seg = ReduceLROnPlateau(optimizer_seg, mode='min', factor=0.2, patience=5, min_lr = MAX_LR, verbose=True)\n",
    "\n",
    "optimizer_dismain = optim.Adam(model_dismain.parameters(), lr=LEARNING_RATE_DIS, betas=(0.9, 0.999))\n",
    "# scheduler_dis = ReduceLROnPlateau(optimizer_dismain, mode='min', factor=0.2, patience=5, min_lr = MAX_LR, verbose=True)\n",
    "accuracy_train_metric = Accuracy(task='binary')\n",
    "accuracy_val_metric = Accuracy(task='binary')\n",
    "accuracy_train_metric = accuracy_train_metric.to(device)\n",
    "accuracy_val_metric = accuracy_val_metric.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(LEARNING_RATE_SEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_name  = 'en_dis_0305'\n",
    "writer = SummaryWriter('runs/' + log_name)\n",
    "csv_file = open(log_name + '.csv', mode='w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow([\n",
    "    \"Epoch\", \"Epoch Time (mins)\", \n",
    "    \"Train Seg Loss\", \"Val Seg Loss\",\n",
    "    \"Train Dice Loss\", \"Val Dice Loss\",\n",
    "    \"Train Adv Loss\", \"Val Adv Loss\",\n",
    "    \"Train Dis Loss\", \"Val Dis Loss\", \n",
    "    \"Train Accuracy\", \"Val Accuracy\", \n",
    "    \"Seg LR\", \"Dis LR\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    model_seg.train()\n",
    "    model_dismain.train()\n",
    "    torch.cuda.empty_cache()\n",
    "    segloss_b_t = []\n",
    "    diceloss_b_t = []\n",
    "    advloss_b_t = []\n",
    "    disloss_b_t = []\n",
    "    epoch_start_time = time.time()\n",
    "    for i, (batch_s) in enumerate(train_loader_s):\n",
    "        optimizer_seg.zero_grad()\n",
    "        optimizer_dismain.zero_grad()\n",
    "        \n",
    "        batch_t = next(target_loader_cycle)\n",
    "        \n",
    "        image_s, label_s = batch_s\n",
    "        image_t, label_t = batch_t\n",
    "        image_s, label_s = image_s.to(device), label_s.to(device)\n",
    "        image_s = norm_image(image_s) #color normalization\n",
    "#         label_s = label_s.permute(0, 3, 1, 2)\n",
    "\n",
    "        image_t, label_t = image_t.to(device), label_t.to(device)\n",
    "        image_t = norm_image(image_t) #color normalization\n",
    "#         label_t = label_t.permute(0, 3, 1, 2)\n",
    "\n",
    "        #train discriminator model - start\n",
    "        for param in model_dismain.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        pred_s = model_seg(image_s).detach()\n",
    "        pred_t = model_seg(image_t).detach()\n",
    "        dis_output_s = model_dismain(pred_s)\n",
    "        dis_output_t = model_dismain(pred_t)\n",
    "\n",
    "        loss_dis_source = BCE_LOSS(dis_output_s, torch.FloatTensor(dis_output_s.data.size()).fill_(source_label).to(device))\n",
    "        loss_dis_target = BCE_LOSS(dis_output_t, torch.FloatTensor(dis_output_t.data.size()).fill_(target_label).to(device))\n",
    "        loss_dis = (loss_dis_target + loss_dis_source)\n",
    "        disloss_b_t.append(loss_dis.data.cpu().numpy())\n",
    "        loss_dis_source.backward()\n",
    "        loss_dis_target.backward()\n",
    "#         loss_dis.backward()\n",
    "        optimizer_dismain.step()\n",
    "        #train discriminator model - end\n",
    "\n",
    "        #train segmentation model - start\n",
    "        for param in model_dismain.parameters():\n",
    "            param.requires_grad = False\n",
    "                    \n",
    "        pred_s = model_seg(image_s)\n",
    "        loss_seg = BCE_LOSS(pred_s, label_s)\n",
    "        pred_s = torch.sigmoid(pred_s)\n",
    "        pred_binary = (pred_s > 0.5).float()\n",
    "        pred_binary = pred_binary.to(device)\n",
    "        dice_loss = diceLoss(pred_s, label_s)        \n",
    "        accuracy_train_metric(pred_binary, label_s)\n",
    "        segloss_b_t.append(loss_seg.data.cpu().numpy())\n",
    "        diceloss_b_t.append(dice_loss.data.cpu().numpy())\n",
    "        (0.7 * loss_seg).backward(retain_graph=True)\n",
    "        (0.3 * dice_loss).backward(retain_graph=True)\n",
    "        #train segmentation model - end\n",
    "        \n",
    "        #Adv loss to segmentation model - start\n",
    "        pred_t = model_seg(image_t)\n",
    "        dis_output_t = model_dismain(pred_t)\n",
    "        loss_adv_target = LAMBDA_ADV*BCE_LOSS(dis_output_t, torch.FloatTensor(dis_output_t.data.size()).fill_(source_label).to(device))\n",
    "        advloss_b_t.append(loss_adv_target.data.cpu().numpy())\n",
    "        loss_adv_target.backward(retain_graph=True)\n",
    "        #Adv loss to segmentation model - end\n",
    "        optimizer_seg.step()\n",
    "        \n",
    "    #Batch loop ends here\n",
    "    segloss_train = np.mean(segloss_b_t)\n",
    "    diceLoss_train = np.mean(diceloss_b_t)\n",
    "    advloss_train = np.mean(advloss_b_t)\n",
    "    disloss_train = np.mean(disloss_b_t)\n",
    "    accuracy_train = accuracy_train_metric\n",
    "    accuracy_train = accuracy_train.compute()\n",
    "    accuracy_train_metric.reset()\n",
    "    \n",
    "    model_seg.eval()\n",
    "    model_dismain.eval()\n",
    "    segloss_b_v = []\n",
    "    diceloss_b_v = []\n",
    "    advloss_b_v = []\n",
    "    disloss_b_v = []\n",
    "    with torch.no_grad():\n",
    "        for i, data_vs in enumerate(val_loader_s):\n",
    "            image_vs, label_vs = data_vs\n",
    "            image_vs = image_vs.to(device)\n",
    "            label_vs = label_vs.to(device)\n",
    "            image_vs = norm_image(image_vs) #color normalization\n",
    "            voutput_s = model_seg(image_vs)\n",
    "#             label_vs = label_vs.permute(0, 3, 1, 2)\n",
    "            vloss = BCE_LOSS(voutput_s, label_vs) #seg loss on source val\n",
    "            voutput_s = torch.sigmoid(voutput_s)\n",
    "            voutputs_binary_s = (voutput_s > 0.5).float()\n",
    "            voutputs_binary_s = voutputs_binary_s.to(device)\n",
    "            dice_loss = diceLoss(voutput_s, label_vs) #dice score on source val\n",
    "            \n",
    "            batch_vt = next(valtarget_loader_cycle)\n",
    "            input_vt, label_vt = batch_vt\n",
    "            input_vt = input_vt.to(device)\n",
    "            label_vt = label_vt.to(device)\n",
    "            input_vt = norm_image(input_vt) #color normalization\n",
    "            voutput_t = model_seg(input_vt)\n",
    "#             label_vt = label_vt.permute(0, 3, 1, 2)\n",
    "            voutputs_binary_t = (torch.sigmoid(voutput_t) > 0.5).float()\n",
    "            voutputs_binary_t = voutputs_binary_t.to(device)\n",
    "\n",
    "            dis_output_t = model_dismain(voutput_t)\n",
    "            loss_adv_target = LAMBDA_ADV*BCE_LOSS(dis_output_t, torch.FloatTensor(dis_output_t.data.size()).fill_(source_label).to(device)) #adv loss on target val\n",
    "\n",
    "            dis_output_s = model_dismain(voutput_s)\n",
    "            loss_dis_source = BCE_LOSS(dis_output_s, torch.FloatTensor(dis_output_s.data.size()).fill_(source_label).to(device)) #dis loss on source val\n",
    "            loss_dis_target = BCE_LOSS(dis_output_t, torch.FloatTensor(dis_output_t.data.size()).fill_(target_label).to(device)) #dis loss on target val\n",
    "            loss_dis = loss_dis_target + loss_dis_source\n",
    "\n",
    "            advloss_b_v.append(loss_adv_target.data.cpu().numpy())\n",
    "            segloss_b_v.append(vloss.data.cpu().numpy())\n",
    "            diceloss_b_v.append(dice_loss.data.cpu().numpy())\n",
    "            disloss_b_v.append(loss_dis.data.cpu().numpy())\n",
    "            accuracy_val_metric(voutputs_binary_s, label_vs)\n",
    "        #val_loader_s loop ends here\n",
    "    #no grad ends here\n",
    "    accuracy_val = accuracy_val_metric\n",
    "    accuracy_val = accuracy_val.compute()\n",
    "    segloss_val = np.mean(segloss_b_v)\n",
    "    diceLoss_val = np.mean(diceloss_b_v)\n",
    "    advloss_val = np.mean(advloss_b_v)\n",
    "    disloss_val = np.mean(disloss_b_v)\n",
    "    accuracy_val_metric.reset() \n",
    "    epoch_end_time = time.time()\n",
    "    epoch_time = (epoch_end_time - epoch_start_time) / 60\n",
    "    for param_group in optimizer_seg.param_groups:\n",
    "        seglr = param_group['lr']\n",
    "    for param_group in optimizer_dismain.param_groups:\n",
    "        dislr = param_group['lr']\n",
    "\n",
    "#     print('[Epoch:{}, {:.2f}mins] Train Seg Loss: {:.2f}, Val Seg Loss: {:.2f}, Train Dice Score: {:.2f}, Val Dice Score: {:.2f}, '\n",
    "#       'Train Adv Loss: {:.2f}, Val Adv Loss: {:.2f}, Train Dis Loss: {:.2f}, Val Dis Loss: {:.2f}, Train Dec Loss: {:.2f},'\n",
    "#       'Val Dec Loss: {:.2f}'.format(epoch+1, epoch_time, segloss_train, segloss_val, diceLoss_train, diceLoss_val, advloss_train, advloss_val, disloss_train, disloss_val))\n",
    "    #update learning rate\n",
    "#     scheduler_seg.step(segloss_val)\n",
    "#     scheduler_dis.step(disloss_val)\n",
    "\n",
    "    #csv writer\n",
    "    csv_writer.writerow([\n",
    "        epoch + 1, epoch_time, \n",
    "        segloss_train, segloss_val, \n",
    "        diceLoss_train, diceLoss_val, \n",
    "        advloss_train, advloss_val, \n",
    "        disloss_train, disloss_val,\n",
    "        accuracy_train.item(), accuracy_val.item(),\n",
    "        seglr, dislr\n",
    "    ])\n",
    "    csv_file.flush() \n",
    "    #model save\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        torch.save(model_seg, log_name+'.pth')\n",
    "#epoch loop ends here\n",
    "csv_file.close()\n",
    "torch.save(model_seg, log_name+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_seg, log_name+'.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(train_loader_s))\n",
    "\n",
    "# Extract the image and mask from the batch\n",
    "image, mask = batch\n",
    "\n",
    "# Convert the image and mask to numpy arrays\n",
    "image = image.numpy()\n",
    "mask = mask.numpy()\n",
    "# Plot the image and mask\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].imshow(image[0])\n",
    "ax[0].set_title('Image')\n",
    "ax[1].imshow(mask[0], cmap='gray')\n",
    "ax[1].set_title('Mask')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model_seg, 'udapy_0212.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param_group in optimizer_dismain.param_groups:\n",
    "        lr = param_group['lr']\n",
    "print(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seg = torch.load('en_dis_0305.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seg.eval()\n",
    "def visualize_prediction(test_image, ground_truth, predicted_mask, dice_score):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # Test Image\n",
    "    axes[0].imshow(test_image)  # Permute for correct shape (H, W, C)\n",
    "    axes[0].set_title('Test Image')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Ground Truth\n",
    "    axes[1].imshow(ground_truth)  # Squeeze to remove channel dimension\n",
    "    axes[1].set_title('Ground Truth')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # Predicted Mask\n",
    "    axes[2].imshow(predicted_mask)  # Squeeze to remove channel dimension\n",
    "    axes[2].set_title(f'Predicted Mask\\nDice Coeff: {dice_score:.4f}')\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "dice_scores_s = []   \n",
    "with torch.no_grad():\n",
    "    for i, (test_image, ground_truth) in enumerate(test_loader_s):\n",
    "        test_image = test_image.to(device)\n",
    "        ground_truth = ground_truth.to(device)\n",
    "        \n",
    "        test_image = norm_image(test_image)\n",
    "        preds = model_seg(test_image)\n",
    "        preds = (preds > 0.5).float()\n",
    "        test_image = test_image.permute(0, 2, 3, 1)\n",
    "        tm = test_image[0].cpu().numpy()\n",
    "#         ground_truth = ground_truth.permute(0, 3, 1, 2)\n",
    "        preds = preds.permute(0, 2, 3, 1)\n",
    "        ground_truth = ground_truth.permute(0, 2, 3, 1)\n",
    "        dice_score = dice_coef(ground_truth, preds)\n",
    "        dice_scores_s.append(dice_score.cpu().numpy())\n",
    "#         visualize_prediction(tm, ground_truth[0].cpu().numpy(), preds[0].cpu().numpy(), dice_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source dice score: 0.91261804\n"
     ]
    }
   ],
   "source": [
    "print('source dice score:',np.mean(dice_scores_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seg.eval()\n",
    "def visualize_prediction(test_image, ground_truth, predicted_mask, dice_score):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # Test Image\n",
    "    axes[0].imshow(test_image)  # Permute for correct shape (H, W, C)\n",
    "    axes[0].set_title('Test Image')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Ground Truth\n",
    "    axes[1].imshow(ground_truth)  # Squeeze to remove channel dimension\n",
    "    axes[1].set_title('Ground Truth')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # Predicted Mask\n",
    "    axes[2].imshow(predicted_mask)  # Squeeze to remove channel dimension\n",
    "    axes[2].set_title(f'Predicted Mask\\nDice Coeff: {dice_score:.4f}')\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "dice_scores_t = []   \n",
    "with torch.no_grad():\n",
    "    for i, (test_image, ground_truth) in enumerate(test_loader_t):\n",
    "        test_image = test_image.to(device)\n",
    "        ground_truth = ground_truth.to(device)\n",
    "        \n",
    "        test_image = norm_image(test_image)\n",
    "        preds = model_seg(test_image)\n",
    "        preds = (preds > 0.5).float()\n",
    "        test_image = test_image.permute(0, 2, 3, 1)\n",
    "        tm = test_image[0].cpu().numpy()\n",
    "#         ground_truth = ground_truth.permute(0, 3, 1, 2)\n",
    "        preds = preds.permute(0, 2, 3, 1)\n",
    "        ground_truth = ground_truth.permute(0, 2, 3, 1)\n",
    "        dice_score = dice_coef(ground_truth, preds)\n",
    "        dice_scores_t.append(dice_score.cpu().numpy())\n",
    "#         visualize_prediction(tm, ground_truth[0].cpu().numpy(), preds[0].cpu().numpy(), dice_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6695752\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(dice_scores_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_scores_t2 = []   \n",
    "with torch.no_grad():\n",
    "    for i, (test_image, ground_truth) in enumerate(test_loader_t):\n",
    "        test_image = test_image.to(device)\n",
    "        ground_truth = ground_truth.to(device)\n",
    "        \n",
    "        test_image = norm_image(test_image)\n",
    "        preds = model_seg(test_image)\n",
    "        preds = (preds > 0.5).float()\n",
    "        test_image = test_image.permute(0, 2, 3, 1)\n",
    "        tm = test_image[0].cpu().numpy()\n",
    "#         ground_truth = ground_truth.permute(0, 3, 1, 2)\n",
    "        preds = preds.permute(0, 2, 3, 1)\n",
    "        ground_truth = ground_truth.permute(0, 2, 3, 1)\n",
    "        dice_score = dice_coef(ground_truth, preds)\n",
    "        if(np.sum(ground_truth.cpu().numpy())>8000):\n",
    "            dice_scores_t2.append(dice_score.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76928437\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(dice_scores_t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seg = torch.load('saved_model/udapy_2811.pth')\n",
    "model_seg = model_seg.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsi_path = 'aidpth_test_wsi/VUHSK_1992_2.ome.tif'\n",
    "wsi = tifi.imread(wsi_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = wsi_path.split('/')[1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26188, 4393, 3)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stride = 512\n",
    "patch_size = 512\n",
    "location = [0, 255]\n",
    "\n",
    "# Example WSI dimensions (replace with actual WSI shape)\n",
    "width, height, _ = wsi.shape  # Assuming `wsi` is your input WSI\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the output masks\n",
    "img = np.zeros([width, height], dtype=np.float32)\n",
    "img_final_th = np.zeros([width, height], dtype=bool)\n",
    "count = 0\n",
    "\n",
    "# Loop through locations\n",
    "for eh in tqdm(location, desc=\"Processing patches at locations\"):\n",
    "    h = eh\n",
    "    while h < height:\n",
    "        w = eh\n",
    "        while w < width:\n",
    "            # Extract patch\n",
    "            wsi_region = wsi[w:w + patch_size, h:h + patch_size]\n",
    "\n",
    "            # Pad if the patch is smaller than the required size\n",
    "            if wsi_region.shape[0] < patch_size or wsi_region.shape[1] < patch_size:\n",
    "                padded_patch = np.zeros((patch_size, patch_size, 3), dtype=np.float32)\n",
    "                padded_patch[:wsi_region.shape[0], :wsi_region.shape[1]] = wsi_region\n",
    "                input_patch = padded_patch\n",
    "            else:\n",
    "                input_patch = wsi_region\n",
    "\n",
    "            # Prepare the patch for model inference\n",
    "#             input_patch = np.array(input_patch).transpose(0,1,2)  # Convert to (C, H, W)\n",
    "            input_patch = torch.tensor(input_patch, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "            input_patch = input_patch.permute(0, 3, 1, 2)\n",
    "#             print(input_patch.shape)\n",
    "            input_patch = norm_image(input_patch)\n",
    "            # Perform inference with the PyTorch model\n",
    "            with torch.no_grad():\n",
    "                input_patch = norm_image(input_patch)\n",
    "                output = model_seg(input_patch)\n",
    "                output = torch.sigmoid(output)  # Assuming binary output\n",
    "                output = output.squeeze().cpu().numpy()\n",
    "                output = np.where(output >= 0.5, 1, 0)\n",
    "                input_patch = input_patch.permute(0, 2, 3, 1)\n",
    "                # Visualization for patches with positive predictions\n",
    "#                 sum_score = np.sum(output)\n",
    "#                 if sum_score > 0:\n",
    "#                     fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "#                     # Test Image\n",
    "#                     axes[0].imshow(input_patch[0].cpu().numpy())  # (H, W, C)\n",
    "#                     axes[0].set_title('Test Image')\n",
    "#                     axes[0].axis('off')\n",
    "\n",
    "#                     # Predicted Mask\n",
    "#                     axes[1].imshow(output, cmap='gray')  # Binary mask\n",
    "#                     axes[1].set_title(f'Predicted Mask\\nSum count: {sum_score}')\n",
    "#                     axes[1].axis('off')\n",
    "\n",
    "#                     plt.show()\n",
    "\n",
    "                # Save the patch output into the final image\n",
    "                w_end = min(w + patch_size, width)\n",
    "                h_end = min(h + patch_size, height)\n",
    "                img[w:w_end, h:h_end] = output[:w_end - w, :h_end - h]\n",
    "\n",
    "            w += stride\n",
    "\n",
    "        h += stride\n",
    "\n",
    "    # Threshold the output image for the current iteration\n",
    "    img1_th = np.where(img >= 0.5, 1, 0)\n",
    "    img_final_th = np.logical_or(img_final_th, img1_th)\n",
    "\n",
    "    # Reset `img` for the next iteration\n",
    "    img = np.zeros([width, height], dtype=np.float32)\n",
    "\n",
    "    print(f'Completed iteration {count + 1}, img shape: {img1_th.shape}, img_final_th shape: {img_final_th.shape}')\n",
    "    count += 1\n",
    "\n",
    "# Final mask\n",
    "img_final_th = img_final_th.astype(np.uint8) \n",
    "plt.imsave('output/'+ fname+ '_0403.png', img_final_th, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "width,height,_ =wsi.shape\n",
    "\n",
    "stride = 512\n",
    "patch_size = 512\n",
    "location = [0, 255]\n",
    "\n",
    "img = np.zeros([width, height], dtype=np.float32)\n",
    "img_final_th = np.zeros([width,height])\n",
    "count = 0\n",
    "\n",
    "# Loop through locations\n",
    "for eh in tqdm(location, desc=\"Processing patches at locations\"):\n",
    "    h = eh\n",
    "    while h < height:\n",
    "        w = eh\n",
    "        while w < width:\n",
    "            wsi_region = wsi[w:w + patch_size, h:h + patch_size]  # Extract patch\n",
    "            \n",
    "            if wsi_region.shape[0] < patch_size or wsi_region.shape[1] < patch_size:\n",
    "                padded_patch = np.zeros([patch_size, patch_size, 3], dtype=np.float32)\n",
    "                padded_patch[0:wsi_region.shape[0], 0:wsi_region.shape[1]] = wsi_region\n",
    "                input_patch = padded_patch\n",
    "            else:\n",
    "                input_patch = wsi_region\n",
    "\n",
    "                input_patch = np.array(input_patch).transpose(0,1,2)\n",
    "                input_patch = torch.tensor(input_patch, dtype=torch.float32).unsqueeze(0).to(device)\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    \n",
    "                    output = model_seg(input_patch)\n",
    "                    output = torch.sigmoid(output) \n",
    "                    output = output.squeeze().cpu().numpy()\n",
    "                    \n",
    "                    output = np.where(output >= 0.5, 1, 0)\n",
    "                    sum_score = np.sum(output)\n",
    "                    if sum_score>0:\n",
    "                        fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "                        # Test Image\n",
    "                        axes[0].imshow(wsi_region)  # Permute for correct shape (H, W, C)\n",
    "                        axes[0].set_title('Test Image')\n",
    "                        axes[0].axis('off')\n",
    "\n",
    "\n",
    "                        # Predicted Mask\n",
    "                        axes[1].imshow(output)  # Squeeze to remove channel dimension\n",
    "                        axes[1].set_title(f'Predicted Mask\\nsum count: {sum_score}')\n",
    "                        axes[1].axis('off')\n",
    "\n",
    "                        plt.show()\n",
    "                # Save the output in the final image\n",
    "                \n",
    "                img[w:w + patch_size, h:h + patch_size] = output\n",
    "\n",
    "#             print(f\"Processed patch at (h={h}, w={w})\")\n",
    "            w += stride\n",
    "\n",
    "        h += stride\n",
    "\n",
    "    # Threshold the output image\n",
    "    img1_th = np.where(img >= 0.5, 1, 0)\n",
    "    img_final_th = np.logical_or(img_final_th, img1_th)\n",
    "\n",
    "    # Reset img for the next iteration\n",
    "    img = np.zeros([width, height], dtype=np.float32)\n",
    "    \n",
    "    print(f'Completed iteration {count + 1}, img shape: {img1_th.shape}, img_final_th shape: {img_final_th.shape}')\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imsave('output/14218B_24_2811.png',img_final_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(img_final_th)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_loader_cycle = itertools.cycle(train_loader_s)\n",
    "for i, (batch_s) in enumerate(train_loader_s):\n",
    "    batch_t = next(target_loader_cycle)\n",
    "    image_t, label_t = batch_t\n",
    "    label_t = label_t / 255.\n",
    "    label_t = (label_t > 0.5).float()\n",
    "    pc = np.sum(np.array(label_t))\n",
    "    if pc<5000:\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "        image_t = image_t.cpu().numpy().astype('uint8')\n",
    "\n",
    "        # Test Image\n",
    "        axes[0].imshow(image_t[0])  # Permute for correct shape (H, W, C)\n",
    "        axes[0].set_title('Test Image')\n",
    "        axes[0].axis('off')\n",
    "        # Ground Truth\n",
    "        axes[1].imshow(label_t[0])  # Squeeze to remove channel dimension\n",
    "        axes[1].set_title(f'Ground Truth (Sum: {pc:.2f})')\n",
    "        axes[1].axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (batch_s) in enumerate(train_loader_s):\n",
    "    image_t, label_t = batch_s\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    image_t = image_t.cpu().numpy().astype('uint8')\n",
    "\n",
    "    # Test Image\n",
    "    axes[0].imshow(image_t[0])  \n",
    "    axes[0].set_title('Test Image')\n",
    "    axes[0].axis('off')\n",
    "    # Ground Truth\n",
    "    axes[1].imshow(label_t[0]) \n",
    "    axes[1].set_title(f'Ground Truth (Sum: {pc:.2f})')\n",
    "    axes[1].axis('off')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
