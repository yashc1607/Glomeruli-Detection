{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import time\n",
    "import torch\n",
    "import itertools \n",
    "import numpy as np\n",
    "import imagecodecs\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import tifffile as tifi\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision import transforms\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchmetrics import Accuracy, Metric\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAMBDA_ADV = 0.1\n",
    "MAX_LR = 0.0001\n",
    "LEARNING_RATE_SEG = 0.00001\n",
    "LEARNING_RATE_DIS = 0.0001\n",
    "BATCH_SIZE = 8\n",
    "BCE_LOSS = torch.nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageMaskDataset(Dataset):\n",
    "    def __init__(self, images, masks):\n",
    "        self.images = images  # Keep as NumPy arrays, not torch tensors\n",
    "        self.masks = masks\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = torch.from_numpy(self.images[idx]).permute(2, 0, 1).float()\n",
    "        mask = torch.from_numpy(self.masks[idx]).permute(2, 0, 1).float()\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = 'overlap_patch/img'\n",
    "mask_dir = 'overlap_patch/mask'\n",
    "\n",
    "image_dataset = [] \n",
    "mask_dataset = []\n",
    "\n",
    "imgNames = os.listdir(image_dir)\n",
    "imgAddr = image_dir + '/'\n",
    "maskAddr = mask_dir + '/'\n",
    "\n",
    "count = 0\n",
    "\n",
    "for i in tqdm(range(len(imgNames)), desc=\"Processing images\"):\n",
    "# for i in tqdm(range(200), desc=\"Processing images\"):\n",
    "    try:\n",
    "        mask = cv2.imread(maskAddr + imgNames[i], 0) \n",
    "        mask = Image.fromarray(mask)\n",
    "        mask_array = np.array(mask)\n",
    "        \n",
    "        if np.sum(mask_array) > 8000:\n",
    "            image = cv2.imread(imgAddr + imgNames[i], cv2.IMREAD_COLOR)  \n",
    "            image = Image.fromarray(image)\n",
    "            image_dataset.append(np.array(image))\n",
    "            mask_dataset.append(np.array(mask))\n",
    "            count += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {imgNames[i]}: {e}\")\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagebg_dir = 'train_dataset/img_ng'\n",
    "maskbg_dir = 'train_dataset/mask_ng'\n",
    "\n",
    "imgbgNames = os.listdir(imagebg_dir)\n",
    "imgbgAddr = imagebg_dir + '/'\n",
    "maskbgAddr = maskbg_dir + '/'\n",
    "target_count = count\n",
    "valid_count = 0\n",
    "for i in tqdm(range(len(imgbgNames)), desc=\"Processing images\"):\n",
    "    if valid_count >= target_count:\n",
    "        break  # Stop once we reach the desired count\n",
    "\n",
    "#     try:\n",
    "        # Read the mask in grayscale\n",
    "    mask = cv2.imread(maskbgAddr + imgbgNames[i], 0)\n",
    "    if mask is None:\n",
    "        raise ValueError(\"Mask is None\")\n",
    "\n",
    "    # Normalize and binarize\n",
    "    mask = mask / 255.\n",
    "    mask = (mask > 0.5).astype(int)\n",
    "\n",
    "    # Skip if mask has any foreground (non-zero)\n",
    "    if np.sum(mask) != 0:\n",
    "        continue\n",
    "\n",
    "    # Read the corresponding image\n",
    "    image = cv2.imread(imgbgAddr + imgbgNames[i], cv2.IMREAD_COLOR)\n",
    "    if image is None:\n",
    "        raise ValueError(\"Image is None\")\n",
    "\n",
    "    image = Image.fromarray(image)\n",
    "\n",
    "    # Add to datasets\n",
    "    image_dataset.append(np.array(image))\n",
    "    mask_dataset.append(np.array(mask))\n",
    "    valid_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dataset = np.array(image_dataset)  \n",
    "mask_dataset = np.array(mask_dataset)    \n",
    "\n",
    "image_dataset = np.expand_dims(image_dataset, axis=3)\n",
    "image_dataset = np.squeeze(image_dataset)\n",
    "mask_dataset = np.expand_dims(mask_dataset, axis=3)\n",
    "\n",
    "source_img_train, source_img_test, source_mask_train, source_mask_test = train_test_split(\n",
    "    image_dataset, mask_dataset, test_size=0.3, random_state=44, shuffle=True)\n",
    "del image_dataset, mask_dataset\n",
    "source_img_val, source_img_test, source_mask_val, source_mask_test = train_test_split(\n",
    "    source_img_test, source_mask_test, test_size=0.2, random_state=44, shuffle=True)\n",
    "\n",
    "print(f\"Total processed images: {count}\")\n",
    "print(f\"Training set size: {len(source_img_train)}, Validation set size: {len(source_img_val)}, Test set size: {len(source_img_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_s = ImageMaskDataset(source_img_train, source_mask_train)\n",
    "val_dataset_s = ImageMaskDataset(source_img_val, source_mask_val)\n",
    "test_dataset_s = ImageMaskDataset(source_img_test, source_mask_test)\n",
    "\n",
    "train_loader_s = DataLoader(train_dataset_s, batch_size=8, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader_s = DataLoader(val_dataset_s, batch_size=8, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader_s = DataLoader(test_dataset_s, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del source_img_train, source_img_test, source_mask_train, source_mask_test, source_img_val, source_mask_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_image_dir = 'aidpath_target/images_512'\n",
    "target_mask_dir = 'aidpath_target/masks_512'\n",
    "target_image = [] \n",
    "target_mask= []\n",
    "imgNames = os.listdir(target_image_dir)\n",
    "imgAddr = target_image_dir + '/'\n",
    "maskAddr = target_mask_dir + '/'\n",
    "count = 0\n",
    "\n",
    "for i in tqdm(range(len(imgNames)), desc=\"Processing images\"):\n",
    "# for i in tqdm(range(200), desc=\"Processing images\"):\n",
    "    try:\n",
    "        mask = cv2.imread(maskAddr + imgNames[i], 0) \n",
    "#         mask = Image.fromarray(mask)\n",
    "        mask_array = np.array(mask)\n",
    "        \n",
    "        if np.sum(mask_array) > 0:\n",
    "            image = cv2.imread(imgAddr + imgNames[i], cv2.IMREAD_COLOR)  \n",
    "            mask = mask / 255.\n",
    "            mask = (mask > 0.5).astype(int)\n",
    "            target_image.append(np.array(image))\n",
    "            target_mask.append(np.array(mask))\n",
    "#             break\n",
    "            count += 1\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {imgNames[i]}: {e}\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageMaskDataset1(Dataset):\n",
    "    def __init__(self, images, masks, exists):\n",
    "        self.images = images  # NumPy arrays\n",
    "        self.masks = masks\n",
    "        self.exists = exists  # 1D array of 0s and 1s\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = torch.from_numpy(self.images[idx]).permute(2, 0, 1).float()\n",
    "        mask = torch.from_numpy(self.masks[idx]).permute(2, 0, 1).float()\n",
    "        exist = torch.tensor(self.exists[idx]).float()\n",
    "        return image, mask, exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_image = np.array(target_image)  \n",
    "target_mask = np.array(target_mask) \n",
    "\n",
    "target_image = np.expand_dims(target_image, axis=3)\n",
    "target_image = np.squeeze(target_image)\n",
    "target_mask = np.expand_dims(target_mask, axis=3)\n",
    "\n",
    "target_train_image, target_test_image, target_train_mask, target_test_mask = train_test_split(\n",
    "    target_image, target_mask, test_size=0.1, random_state=44, shuffle=True)\n",
    "\n",
    "target_val_image, target_test_image, target_val_mask, target_test_mask = train_test_split(\n",
    "    target_test_image, target_test_mask, test_size=0.2, random_state=44, shuffle=True)\n",
    "\n",
    "print(f\"Total processed images: {count}\")\n",
    "print(f\"Training set size: {len(target_train_image)}, Validation set size: {len(target_val_image)}, Test set size: {len(target_test_image)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_exists = np.ones_like(target_train_image)\n",
    "train_exists = np.ones((target_train_image.shape[0],), dtype=np.float32)\n",
    "# Set 50% of the entries to 0\n",
    "num_zeros = train_exists.shape[0] // 2\n",
    "zero_indices = np.random.choice(train_exists.shape[0], size=num_zeros, replace=False)\n",
    "train_exists[zero_indices] = 0\n",
    "\n",
    "val_exists = np.ones_like(target_val_image)\n",
    "val_exists = np.ones((target_val_image.shape[0],), dtype=np.float32)\n",
    "# Set 50% of the entries to 0\n",
    "num_zeros = val_exists.shape[0] // 2\n",
    "zero_indices = np.random.choice(val_exists.shape[0], size=num_zeros, replace=False)\n",
    "val_exists[zero_indices] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset_t = ImageMaskDataset1(target_train_image, target_train_mask, train_exists)\n",
    "val_dataset_t = ImageMaskDataset1(target_val_image, target_val_mask, val_exists)\n",
    "test_dataset_t = ImageMaskDataset(target_test_image, target_test_mask)\n",
    "\n",
    "train_loader_t = DataLoader(train_dataset_t, batch_size=8, shuffle=True, num_workers=4, pin_memory=True)\n",
    "val_loader_t = DataLoader(val_dataset_t, batch_size=8, shuffle=False, num_workers=4, pin_memory=True)\n",
    "test_loader_t = DataLoader(test_dataset_t, batch_size=1, shuffle=False, num_workers=4, pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del target_image, target_mask, target_train_image, target_test_image, target_train_mask, target_test_mask, target_val_image, target_val_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(ch_out, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(ch_out)\n",
    "        )\n",
    "        self.residual = nn.Conv2d(ch_in, ch_out, kernel_size=1, stride=1, padding=0, bias=True)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        residual = self.residual(x)\n",
    "        x = self.conv(x)\n",
    "        x += residual  # Residual connection\n",
    "        return self.relu(x)\n",
    "\n",
    "class up_conv(nn.Module):\n",
    "    def __init__(self, ch_in, ch_out):\n",
    "        super(up_conv, self).__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(ch_in, ch_out, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(ch_out),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.up(x)\n",
    "\n",
    "\n",
    "class encoder(nn.Module):\n",
    "    def __init__(self, img_ch=3, output_ch=1):\n",
    "        super(encoder, self).__init__()\n",
    "        \n",
    "        self.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.ResBlock1 = ResidualBlock(ch_in=img_ch, ch_out=64)\n",
    "        self.ResBlock2 = ResidualBlock(ch_in=64, ch_out=128)\n",
    "        self.ResBlock3 = ResidualBlock(ch_in=128, ch_out=256)\n",
    "        self.ResBlock4 = ResidualBlock(ch_in=256, ch_out=512)\n",
    "        self.ResBlock5 = ResidualBlock(ch_in=512, ch_out=1024)\n",
    "        \n",
    "        self.Up5 = up_conv(ch_in=1024, ch_out=512)\n",
    "        self.Up_ResBlock5 = ResidualBlock(ch_in=1024, ch_out=512)\n",
    "        \n",
    "        self.Up4 = up_conv(ch_in=512, ch_out=256)\n",
    "        self.Up_ResBlock4 = ResidualBlock(ch_in=512, ch_out=256)\n",
    "        \n",
    "        self.Up3 = up_conv(ch_in=256, ch_out=128)\n",
    "        self.Up_ResBlock3 = ResidualBlock(ch_in=256, ch_out=128)\n",
    "        \n",
    "        self.Up2 = up_conv(ch_in=128, ch_out=64)\n",
    "        self.Up_ResBlock2 = ResidualBlock(ch_in=128, ch_out=64)\n",
    "\n",
    "        self.Conv_1x1 = nn.Conv2d(64, output_ch, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoding path\n",
    "#         x = x.permute(0, 3, 1, 2)\n",
    "        x1 = self.ResBlock1(x)\n",
    "        x2 = self.Maxpool(x1)\n",
    "        x2 = self.ResBlock2(x2)\n",
    "        \n",
    "        x3 = self.Maxpool(x2)\n",
    "        x3 = self.ResBlock3(x3)\n",
    "\n",
    "        x4 = self.Maxpool(x3)\n",
    "        x4 = self.ResBlock4(x4)\n",
    "\n",
    "        x5 = self.Maxpool(x4)\n",
    "        x5 = self.ResBlock5(x5)\n",
    "\n",
    "        # Decoding + concat path\n",
    "        d5 = self.Up5(x5)\n",
    "        d5 = torch.cat((x4, d5), dim=1)\n",
    "        d5 = self.Up_ResBlock5(d5)\n",
    "        \n",
    "        d4 = self.Up4(d5)\n",
    "        d4 = torch.cat((x3, d4), dim=1)\n",
    "        d4 = self.Up_ResBlock4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        d3 = torch.cat((x2, d3), dim=1)\n",
    "        d3 = self.Up_ResBlock3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        d2 = torch.cat((x1, d2), dim=1)\n",
    "        d2 = self.Up_ResBlock2(d2)\n",
    "\n",
    "        d1 = self.Conv_1x1(d2)\n",
    "#         d1 = d1.permute(0, 2, 3, 1)\n",
    "        return d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCDiscriminator(nn.Module):\n",
    "\n",
    "    def __init__(self, num_classes, ndf=64):\n",
    "        super(FCDiscriminator, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(num_classes, ndf, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(ndf, ndf * 2, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(ndf * 2, ndf * 4, kernel_size=4, stride=2, padding=1)\n",
    "        self.conv4 = nn.Conv2d(ndf * 4, ndf * 8, kernel_size=4, stride=2, padding=1)\n",
    "        self.classifier = nn.Conv2d(ndf * 8, 1, kernel_size=4, stride=2, padding=1)\n",
    "        self.leaky_relu = nn.LeakyReLU(negative_slope=0.2, inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "#         x = x.permute(0, 3, 1, 2)\n",
    "        x = self.conv1(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.leaky_relu(x)\n",
    "        x = self.classifier(x)\n",
    "#         x = x.permute(0, 2, 3, 1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_coef(y_pred, y_true):\n",
    "    smooth = 1.\n",
    "\n",
    "    iflat = y_pred.view(-1)\n",
    "    tflat = y_true.view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "\n",
    "    return ((2. * intersection) + smooth) / (iflat.sum() + tflat.sum() + smooth)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diceLoss(y_pred, y_true):\n",
    "    smooth = 1.\n",
    "\n",
    "    iflat = y_pred.view(-1)\n",
    "    tflat = y_true.view(-1)\n",
    "    intersection = (iflat * tflat).sum()\n",
    "\n",
    "    return 1.0 - ((2. * intersection) + smooth) / (iflat.sum() + tflat.sum() + smooth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_image(image):\n",
    "    min_val = image.min(dim=-1, keepdim=True)[0].min(dim=-2, keepdim=True)[0]  # Get min per channel\n",
    "    max_val = image.max(dim=-1, keepdim=True)[0].max(dim=-2, keepdim=True)[0]  # Get max per channel\n",
    "    \n",
    "    normalized_img = (image - min_val) / (max_val - min_val + 1e-8)  # Add epsilon to avoid division by zero\n",
    "    return normalized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_loader_cycle = itertools.cycle(train_loader_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valtarget_loader_cycle = itertools.cycle(val_loader_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "source_label = 0\n",
    "target_label = 1\n",
    "model_seg = encoder()\n",
    "model_dismain = FCDiscriminator(1)\n",
    "model_seg = model_seg.train()\n",
    "model_dismain = model_dismain.train()\n",
    "model_seg = model_seg.to(device)\n",
    "model_dismain = model_dismain.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_seg = optim.Adam(model_seg.parameters(), lr=LEARNING_RATE_SEG, betas=(0.9, 0.999))\n",
    "# scheduler_seg = ReduceLROnPlateau(optimizer_seg, mode='min', factor=0.2, patience=5, min_lr = MAX_LR, verbose=True)\n",
    "\n",
    "optimizer_dismain = optim.Adam(model_dismain.parameters(), lr=LEARNING_RATE_DIS, betas=(0.9, 0.999))\n",
    "# scheduler_dis = ReduceLROnPlateau(optimizer_dismain, mode='min', factor=0.2, patience=5, min_lr = MAX_LR, verbose=True)\n",
    "accuracy_train_metric = Accuracy(task='binary')\n",
    "accuracy_val_metric = Accuracy(task='binary')\n",
    "accuracy_train_metric = accuracy_train_metric.to(device)\n",
    "accuracy_val_metric = accuracy_val_metric.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(LEARNING_RATE_SEG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_name  = 'ss_en_dis50_3005'\n",
    "writer = SummaryWriter('runs/' + log_name)\n",
    "csv_file = open(log_name + '.csv', mode='w', newline='')\n",
    "csv_writer = csv.writer(csv_file)\n",
    "csv_writer.writerow([\n",
    "    \"Epoch\", \"Epoch Time (mins)\", \n",
    "    \"Train Seg Loss\", \"Val Seg Loss\",\n",
    "    \"Train Dice Loss\", \"Val Dice Loss\",\n",
    "    \"Train Adv Loss\", \"Val Adv Loss\",\n",
    "    \"Train Dis Loss\", \"Val Dis Loss\", \n",
    "    \"Train Accuracy\", \"Val Accuracy\", \n",
    "    \"Seg LR\", \"Dis LR\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_val_dice = 1.0\n",
    "for epoch in range(epochs):\n",
    "    model_seg.train()\n",
    "    model_dismain.train()\n",
    "    torch.cuda.empty_cache()\n",
    "    segloss_b_t = []\n",
    "    diceloss_b_t = []\n",
    "    advloss_b_t = []\n",
    "    disloss_b_t = []\n",
    "    epoch_start_time = time.time()\n",
    "    for i, (batch_s) in enumerate(train_loader_s):\n",
    "        optimizer_seg.zero_grad()\n",
    "        optimizer_dismain.zero_grad()\n",
    "        \n",
    "        batch_t = next(target_loader_cycle)\n",
    "        \n",
    "        image_s, label_s = batch_s\n",
    "        image_t, label_t, exist_t = batch_t\n",
    "        image_s, label_s = image_s.to(device), label_s.to(device)\n",
    "        image_s = norm_image(image_s) #color normalization\n",
    "\n",
    "        image_t, label_t = image_t.to(device), label_t.to(device)\n",
    "        image_t = norm_image(image_t) #color normalization\n",
    "\n",
    "        #train discriminator model - start\n",
    "        for param in model_dismain.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        pred_s = model_seg(image_s).detach()\n",
    "        pred_t = model_seg(image_t).detach()\n",
    "        dis_output_s = model_dismain(pred_s)\n",
    "        dis_output_t = model_dismain(pred_t)\n",
    "\n",
    "        loss_dis_source = BCE_LOSS(dis_output_s, torch.FloatTensor(dis_output_s.data.size()).fill_(source_label).to(device))\n",
    "        loss_dis_target = BCE_LOSS(dis_output_t, torch.FloatTensor(dis_output_t.data.size()).fill_(target_label).to(device))\n",
    "        loss_dis = (loss_dis_target + loss_dis_source)\n",
    "        disloss_b_t.append(loss_dis.data.cpu().numpy())\n",
    "        loss_dis_source.backward()\n",
    "        loss_dis_target.backward()\n",
    "        optimizer_dismain.step()\n",
    "        #train discriminator model - end\n",
    "\n",
    "        #train segmentation model - start\n",
    "        for param in model_dismain.parameters():\n",
    "            param.requires_grad = False\n",
    "                    \n",
    "        pred_s = model_seg(image_s)\n",
    "        pred_t = model_seg(image_t)\n",
    "        loss_seg = BCE_LOSS(pred_s, label_s)\n",
    "        indices = (exist_t == 1)\n",
    "\n",
    "        # Apply loss only to valid indices\n",
    "        if indices.any():\n",
    "            loss_seg = loss_seg + BCE_LOSS(pred_t[indices], label_t[indices])\n",
    "#             print(indices)\n",
    "        pred_s = torch.sigmoid(pred_s)\n",
    "        pred_binary = (pred_s > 0.5).float()\n",
    "        pred_binary = pred_binary.to(device)\n",
    "        dice_loss = diceLoss(pred_s, label_s)\n",
    "\n",
    "        accuracy_train_metric(pred_binary, label_s)\n",
    "        segloss_b_t.append(loss_seg.data.cpu().numpy())\n",
    "        diceloss_b_t.append(dice_loss.data.cpu().numpy())\n",
    "        loss_seg.backward(retain_graph=True)\n",
    "        #train segmentation model - end\n",
    "        \n",
    "        #Adv loss to segmentation model - start\n",
    "        pred_t = model_seg(image_t)\n",
    "        dis_output_t = model_dismain(pred_t)\n",
    "        loss_adv_target = LAMBDA_ADV*BCE_LOSS(dis_output_t, torch.FloatTensor(dis_output_t.data.size()).fill_(source_label).to(device))\n",
    "        advloss_b_t.append(loss_adv_target.data.cpu().numpy())\n",
    "        loss_adv_target.backward(retain_graph=True)\n",
    "        #Adv loss to segmentation model - end\n",
    "        optimizer_seg.step()\n",
    "        \n",
    "    #Batch loop ends here\n",
    "    segloss_train = np.mean(segloss_b_t)\n",
    "    diceLoss_train = np.mean(diceloss_b_t)\n",
    "    advloss_train = np.mean(advloss_b_t)\n",
    "    disloss_train = np.mean(disloss_b_t)\n",
    "    accuracy_train = accuracy_train_metric\n",
    "    accuracy_train = accuracy_train.compute()\n",
    "    accuracy_train_metric.reset()\n",
    "    \n",
    "    model_seg.eval()\n",
    "    model_dismain.eval()\n",
    "    segloss_b_v = []\n",
    "    diceloss_b_v = []\n",
    "    advloss_b_v = []\n",
    "    disloss_b_v = []\n",
    "    with torch.no_grad():\n",
    "        for i, data_vs in enumerate(val_loader_s):\n",
    "            image_vs, label_vs = data_vs\n",
    "            image_vs = image_vs.to(device)\n",
    "            label_vs = label_vs.to(device)\n",
    "            image_vs = norm_image(image_vs) #color normalization\n",
    "\n",
    "            batch_vt = next(valtarget_loader_cycle)\n",
    "            input_vt, label_vt, exist_vt = batch_vt\n",
    "            input_vt = input_vt.to(device)\n",
    "            label_vt = label_vt.to(device)\n",
    "            input_vt = norm_image(input_vt) #color normalization\n",
    "\n",
    "            voutput_s = model_seg(image_vs)\n",
    "            voutput_t = model_seg(input_vt)\n",
    "            \n",
    "            indices = (exist_vt == 1)\n",
    "            vloss = BCE_LOSS(voutput_s, label_vs)\n",
    "            if indices.any():\n",
    "                vloss = vloss + BCE_LOSS(voutput_t[indices], label_vt[indices])\n",
    "#                 print(indices)\n",
    "            voutput_s = torch.sigmoid(voutput_s)\n",
    "            voutputs_binary_s = (voutput_s > 0.5).float()\n",
    "            voutputs_binary_s = voutputs_binary_s.to(device)\n",
    "            dice_loss = diceLoss(voutput_s, label_vs) #dice score on source val\n",
    "\n",
    "            # voutputs_binary_t = (torch.sigmoid(voutput_t) > 0.5).float()\n",
    "            # voutputs_binary_t = voutputs_binary_t.to(device)\n",
    "\n",
    "            dis_output_t = model_dismain(voutput_t)\n",
    "            loss_adv_target = LAMBDA_ADV*BCE_LOSS(dis_output_t, torch.FloatTensor(dis_output_t.data.size()).fill_(source_label).to(device)) #adv loss on target val\n",
    "\n",
    "            dis_output_s = model_dismain(voutput_s)\n",
    "            loss_dis_source = BCE_LOSS(dis_output_s, torch.FloatTensor(dis_output_s.data.size()).fill_(source_label).to(device)) #dis loss on source val\n",
    "            loss_dis_target = BCE_LOSS(dis_output_t, torch.FloatTensor(dis_output_t.data.size()).fill_(target_label).to(device)) #dis loss on target val\n",
    "            loss_dis = loss_dis_target + loss_dis_source\n",
    "\n",
    "            advloss_b_v.append(loss_adv_target.data.cpu().numpy())\n",
    "            segloss_b_v.append(vloss.data.cpu().numpy())\n",
    "            diceloss_b_v.append(dice_loss.data.cpu().numpy())\n",
    "            disloss_b_v.append(loss_dis.data.cpu().numpy())\n",
    "            accuracy_val_metric(voutputs_binary_s, label_vs)\n",
    "        #val_loader_s loop ends here\n",
    "    #no grad ends here\n",
    "    accuracy_val = accuracy_val_metric\n",
    "    accuracy_val = accuracy_val.compute()\n",
    "    segloss_val = np.mean(segloss_b_v)\n",
    "    diceLoss_val = np.mean(diceloss_b_v)\n",
    "    advloss_val = np.mean(advloss_b_v)\n",
    "    disloss_val = np.mean(disloss_b_v)\n",
    "    accuracy_val_metric.reset() \n",
    "    epoch_end_time = time.time()\n",
    "    epoch_time = (epoch_end_time - epoch_start_time) / 60\n",
    "    for param_group in optimizer_seg.param_groups:\n",
    "        seglr = param_group['lr']\n",
    "    for param_group in optimizer_dismain.param_groups:\n",
    "        dislr = param_group['lr']\n",
    "\n",
    "    #csv writer\n",
    "    csv_writer.writerow([\n",
    "        epoch + 1, epoch_time, \n",
    "        segloss_train, segloss_val, \n",
    "        diceLoss_train, diceLoss_val, \n",
    "        advloss_train, advloss_val, \n",
    "        disloss_train, disloss_val,\n",
    "        accuracy_train.item(), accuracy_val.item(),\n",
    "        seglr, dislr\n",
    "    ])\n",
    "    csv_file.flush() \n",
    "    #model save\n",
    "    if (diceLoss_val < best_val_dice):\n",
    "        best_val_dice = diceLoss_val\n",
    "        torch.save(model_seg, log_name+'.pth')\n",
    "#epoch loop ends here\n",
    "csv_file.close()\n",
    "torch.save(model_seg, log_name+'final.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seg.eval()\n",
    "def visualize_prediction(test_image, ground_truth, predicted_mask, dice_score):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # Test Image\n",
    "    axes[0].imshow(test_image)  # Permute for correct shape (H, W, C)\n",
    "    axes[0].set_title('Test Image')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Ground Truth\n",
    "    axes[1].imshow(ground_truth)  # Squeeze to remove channel dimension\n",
    "    axes[1].set_title('Ground Truth')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # Predicted Mask\n",
    "    axes[2].imshow(predicted_mask)  # Squeeze to remove channel dimension\n",
    "    axes[2].set_title(f'Predicted Mask\\nDice Coeff: {dice_score:.4f}')\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "dice_scores_s = []   \n",
    "with torch.no_grad():\n",
    "    for i, (test_image, ground_truth) in enumerate(test_loader_s):\n",
    "        test_image = test_image.to(device)\n",
    "        ground_truth = ground_truth.to(device)\n",
    "        \n",
    "        test_image = norm_image(test_image)\n",
    "        preds = model_seg(test_image)\n",
    "        preds = (preds > 0.5).float()\n",
    "        test_image = test_image.permute(0, 2, 3, 1)\n",
    "        tm = test_image[0].cpu().numpy()\n",
    "#         ground_truth = ground_truth.permute(0, 3, 1, 2)\n",
    "        preds = preds.permute(0, 2, 3, 1)\n",
    "        ground_truth = ground_truth.permute(0, 2, 3, 1)\n",
    "        dice_score = dice_coef(ground_truth, preds)\n",
    "        dice_scores_s.append(dice_score.cpu().numpy())\n",
    "#         visualize_prediction(tm, ground_truth[0].cpu().numpy(), preds[0].cpu().numpy(), dice_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('source dice score with final saved model:',np.mean(dice_scores_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_scores_t = []   \n",
    "with torch.no_grad():\n",
    "    for i, (test_image, ground_truth) in enumerate(test_loader_t):\n",
    "        test_image = test_image.to(device)\n",
    "        ground_truth = ground_truth.to(device)\n",
    "        \n",
    "        test_image = norm_image(test_image)\n",
    "        preds = model_seg(test_image)\n",
    "        preds = (preds > 0.5).float()\n",
    "        test_image = test_image.permute(0, 2, 3, 1)\n",
    "        tm = test_image[0].cpu().numpy()\n",
    "#         ground_truth = ground_truth.permute(0, 3, 1, 2)\n",
    "        preds = preds.permute(0, 2, 3, 1)\n",
    "        ground_truth = ground_truth.permute(0, 2, 3, 1)\n",
    "        dice_score = dice_coef(ground_truth, preds)\n",
    "        dice_scores_t.append(dice_score.cpu().numpy())\n",
    "#         visualize_prediction(tm, ground_truth[0].cpu().numpy(), preds[0].cpu().numpy(), dice_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('target dice score with final saved model:', np.mean(dice_scores_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_scores_t2 = []   \n",
    "with torch.no_grad():\n",
    "    for i, (test_image, ground_truth) in enumerate(test_loader_t):\n",
    "        test_image = test_image.to(device)\n",
    "        ground_truth = ground_truth.to(device)\n",
    "        \n",
    "        test_image = norm_image(test_image)\n",
    "        preds = model_seg(test_image)\n",
    "        preds = (preds > 0.5).float()\n",
    "        test_image = test_image.permute(0, 2, 3, 1)\n",
    "        tm = test_image[0].cpu().numpy()\n",
    "#         ground_truth = ground_truth.permute(0, 3, 1, 2)\n",
    "        preds = preds.permute(0, 2, 3, 1)\n",
    "        ground_truth = ground_truth.permute(0, 2, 3, 1)\n",
    "        dice_score = dice_coef(ground_truth, preds)\n",
    "        if(np.sum(ground_truth.cpu().numpy())>8000):\n",
    "            dice_scores_t2.append(dice_score.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('target dice score with filter and final saved model:',np.mean(dice_scores_t2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with best saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seg = torch.load('ss_en_dis50_3005.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_seg.eval()\n",
    "def visualize_prediction(test_image, ground_truth, predicted_mask, dice_score):\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # Test Image\n",
    "    axes[0].imshow(test_image)  # Permute for correct shape (H, W, C)\n",
    "    axes[0].set_title('Test Image')\n",
    "    axes[0].axis('off')\n",
    "\n",
    "    # Ground Truth\n",
    "    axes[1].imshow(ground_truth)  # Squeeze to remove channel dimension\n",
    "    axes[1].set_title('Ground Truth')\n",
    "    axes[1].axis('off')\n",
    "\n",
    "    # Predicted Mask\n",
    "    axes[2].imshow(predicted_mask)  # Squeeze to remove channel dimension\n",
    "    axes[2].set_title(f'Predicted Mask\\nDice Coeff: {dice_score:.4f}')\n",
    "    axes[2].axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_scores_s = []   \n",
    "with torch.no_grad():\n",
    "    for i, (test_image, ground_truth) in enumerate(test_loader_s):\n",
    "        test_image = test_image.to(device)\n",
    "        ground_truth = ground_truth.to(device)\n",
    "        \n",
    "        test_image = norm_image(test_image)\n",
    "        preds = model_seg(test_image)\n",
    "        preds = (preds > 0.5).float()\n",
    "        test_image = test_image.permute(0, 2, 3, 1)\n",
    "        tm = test_image[0].cpu().numpy()\n",
    "#         ground_truth = ground_truth.permute(0, 3, 1, 2)\n",
    "        preds = preds.permute(0, 2, 3, 1)\n",
    "        ground_truth = ground_truth.permute(0, 2, 3, 1)\n",
    "        dice_score = dice_coef(ground_truth, preds)\n",
    "        dice_scores_s.append(dice_score.cpu().numpy())\n",
    "print('source dice score with best saved model:',np.mean(dice_scores_s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_scores_t = []   \n",
    "with torch.no_grad():\n",
    "    for i, (test_image, ground_truth) in enumerate(test_loader_t):\n",
    "        test_image = test_image.to(device)\n",
    "        ground_truth = ground_truth.to(device)\n",
    "        \n",
    "        test_image = norm_image(test_image)\n",
    "        preds = model_seg(test_image)\n",
    "        preds = (preds > 0.5).float()\n",
    "        test_image = test_image.permute(0, 2, 3, 1)\n",
    "        tm = test_image[0].cpu().numpy()\n",
    "#         ground_truth = ground_truth.permute(0, 3, 1, 2)\n",
    "        preds = preds.permute(0, 2, 3, 1)\n",
    "        ground_truth = ground_truth.permute(0, 2, 3, 1)\n",
    "        dice_score = dice_coef(ground_truth, preds)\n",
    "        dice_scores_t.append(dice_score.cpu().numpy())\n",
    "print('target dice score with best saved model:',np.mean(dice_scores_t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_scores_t2 = []   \n",
    "with torch.no_grad():\n",
    "    for i, (test_image, ground_truth) in enumerate(test_loader_t):\n",
    "        test_image = test_image.to(device)\n",
    "        ground_truth = ground_truth.to(device)\n",
    "        \n",
    "        test_image = norm_image(test_image)\n",
    "        preds = model_seg(test_image)\n",
    "        preds = (preds > 0.5).float()\n",
    "        test_image = test_image.permute(0, 2, 3, 1)\n",
    "        tm = test_image[0].cpu().numpy()\n",
    "#         ground_truth = ground_truth.permute(0, 3, 1, 2)\n",
    "        preds = preds.permute(0, 2, 3, 1)\n",
    "        ground_truth = ground_truth.permute(0, 2, 3, 1)\n",
    "        dice_score = dice_coef(ground_truth, preds)\n",
    "        if(np.sum(ground_truth.cpu().numpy())>8000):\n",
    "            dice_scores_t2.append(dice_score.cpu().numpy())\n",
    "print('target dice score with filter and best saved model:',np.mean(dice_scores_t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(ground_truth, preds):\n",
    "    \"\"\"Calculate pixel-wise accuracy.\"\"\"\n",
    "    # Flatten the tensors to compare pixel-wise\n",
    "    ground_truth_flat = ground_truth.flatten()\n",
    "    preds_flat = preds.flatten()\n",
    "    correct = (ground_truth_flat == preds_flat).float().sum()\n",
    "    total = ground_truth_flat.numel()\n",
    "    accuracy = correct / total if total > 0 else 0.0\n",
    "    return accuracy\n",
    "\n",
    "def calculate_f1_score(ground_truth, preds):\n",
    "    \"\"\"Calculate F1 score.\"\"\"\n",
    "    # Flatten the tensors\n",
    "    ground_truth_flat = ground_truth.flatten()\n",
    "    preds_flat = preds.flatten()\n",
    "    \n",
    "    # Calculate true positives, false positives, false negatives\n",
    "    tp = ((preds_flat == 1) & (ground_truth_flat == 1)).float().sum()\n",
    "    fp = ((preds_flat == 1) & (ground_truth_flat == 0)).float().sum()\n",
    "    fn = ((preds_flat == 0) & (ground_truth_flat == 1)).float().sum()\n",
    "    \n",
    "    # Calculate precision and recall\n",
    "    precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "    recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "    \n",
    "    # Calculate F1 score\n",
    "    f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_scores_s = []\n",
    "accuracy_scores_s = []\n",
    "f1_scores_s = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (test_image, ground_truth) in enumerate(test_loader_s):\n",
    "        test_image = test_image.to(device)\n",
    "        ground_truth = ground_truth.to(device)\n",
    "        \n",
    "        test_image = norm_image(test_image)\n",
    "        preds = model_seg(test_image)\n",
    "        preds = (preds > 0.5).float()\n",
    "        \n",
    "        # Permute for visualization and metric computation\n",
    "        test_image = test_image.permute(0, 2, 3, 1)\n",
    "        preds = preds.permute(0, 2, 3, 1)\n",
    "        ground_truth = ground_truth.permute(0, 2, 3, 1)\n",
    "        \n",
    "        # Compute metrics for each patch in the batch\n",
    "        for j in range(test_image.shape[0]):  # Loop over each image in the batch\n",
    "            # Dice score\n",
    "            dice_score = dice_coef(ground_truth[j:j+1], preds[j:j+1])\n",
    "            dice_scores_s.append(dice_score.cpu().numpy())\n",
    "            \n",
    "            # Accuracy\n",
    "            accuracy = calculate_accuracy(ground_truth[j:j+1], preds[j:j+1])\n",
    "            accuracy_scores_s.append(accuracy)  # Directly append the float\n",
    "            \n",
    "            # F1 score\n",
    "            f1_score = calculate_f1_score(ground_truth[j:j+1], preds[j:j+1])\n",
    "            f1_scores_s.append(f1_score)  # Directly append the float\n",
    "            \n",
    "            # Visualize (optional: limit to a few to avoid too many plots)\n",
    "            if i % 10 == 0:  # Visualize every 10th batch\n",
    "                tm = test_image[j].cpu().numpy()\n",
    "                visualize_prediction(tm, ground_truth[j].cpu().numpy(), preds[j].cpu().numpy(), dice_score)\n",
    "\n",
    "# Calculate and display the final test metrics\n",
    "final_test_dice = sum(dice_scores_s) / len(dice_scores_s) if dice_scores_s else 0.0\n",
    "final_test_accuracy = sum(accuracy_scores_s) / len(accuracy_scores_s) if accuracy_scores_s else 0.0\n",
    "final_test_f1 = sum(f1_scores_s) / len(f1_scores_s) if f1_scores_s else 0.0\n",
    "\n",
    "print(f'Final Test Dice Score: {final_test_dice:.4f}')\n",
    "print(f'Final Test Accuracy: {final_test_accuracy:.4f}')\n",
    "print(f'Final Test F1 Score: {final_test_f1:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_scores_t2 = []\n",
    "accuracy_scores_t2 = []\n",
    "f1_scores_t2 = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, (test_image, ground_truth) in enumerate(test_loader_t):\n",
    "        test_image = test_image.to(device)\n",
    "        ground_truth = ground_truth.to(device)\n",
    "        \n",
    "        test_image = norm_image(test_image)\n",
    "        preds = model_seg(test_image)\n",
    "        preds = (preds > 0.5).float()\n",
    "        \n",
    "        # Permute for visualization and metric computation\n",
    "        test_image = test_image.permute(0, 2, 3, 1)\n",
    "        tm = test_image[0].cpu().numpy()\n",
    "        preds = preds.permute(0, 2, 3, 1)\n",
    "        ground_truth = ground_truth.permute(0, 2, 3, 1)\n",
    "        \n",
    "        # Compute metrics for the batch\n",
    "        dice_score = dice_coef(ground_truth, preds)\n",
    "        accuracy = calculate_accuracy(ground_truth, preds)\n",
    "        f1_score = calculate_f1_score(ground_truth, preds)\n",
    "        \n",
    "        # Apply the condition for including metrics\n",
    "        if np.sum(ground_truth.cpu().numpy()) > 8000:\n",
    "            dice_scores_t2.append(dice_score.cpu().numpy() if torch.is_tensor(dice_score) else dice_score)\n",
    "            accuracy_scores_t2.append(accuracy)  # Directly append the float\n",
    "            f1_scores_t2.append(f1_score)  # Directly append the float\n",
    "\n",
    "# Calculate and display the final test metrics\n",
    "final_test_dice = sum(dice_scores_t2) / len(dice_scores_t2) if dice_scores_t2 else 0.0\n",
    "final_test_accuracy = sum(accuracy_scores_t2) / len(accuracy_scores_t2) if accuracy_scores_t2 else 0.0\n",
    "final_test_f1 = sum(f1_scores_t2) / len(f1_scores_t2) if f1_scores_t2 else 0.0\n",
    "\n",
    "print(f'Final Test Dice Score: {final_test_dice:.4f}')\n",
    "print(f'Final Test Accuracy: {final_test_accuracy:.4f}')\n",
    "print(f'Final Test F1 Score: {final_test_f1:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
